A sketch on how to make Penn handle Unicode.

Right now, everything's based on c strings where one char is one
character. Everything assumes at best a latin-1 character set. We want
to make Penn Unicode aware.

First step is to make everything use UTF-8 internally, converting
to/from Latin-1 and ASCII as needed in the network layer. I think the
biggest changes to get this basically working will be in the string
and list related functions, and anywhere else that assumes 1 byte is
one complete character.

Also, add a new type, penn_str (or ps for short). This is a
dynamically growable (Replacing the BUFFER_LEN long strings everywhere
and thus hopefully saving memory) string type that is basically C++
std::string. This will require a lot more work to convert everything
but I think it will be worth it.

To add unicode support, I'm currently looking at libunistring, with
libicu as a possible alternative, though that uses utf-16 natively. I
/think/ libunistring and PCRE will work for everything we
need. Another option, since people hate adding new dependencies, is
using pcre and our own utf8 code.

People REALLY don't like the idea of new mandatory dependencies, so
try to make libunistring optional - fall back to slower/degraded
support if absent. Might not have any way to work around lack of iconv
in that case, but that's only going to affect Windows as iconv is part
of unix standards.

With utf-8 and utf-16, characters are multi-byte, but can be
represented by a 32 bit character type. Complicating things are
extended grapheme clusters, where a base character can have multiple
modifiers to add things like accent marks. When it comes to softcode,
a EGC should be treated as a single character (Though this might have
to wait till phase 2). Same in hardcode where it's needed -- reversing
a string, for example. Thus, there will be functions that work with
characters and with EGCs, themselves represented as penn_strs.

